{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fuRE71LaPCA"
      },
      "outputs": [],
      "source": [
        "from utils import process_tweet\n",
        "import pdb\n",
        "from nltk.corpus import stopwords, twitter_samples\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from os import getcwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8sgBs1lasty",
        "outputId": "ef7e07c8-c4da-4240-96a3-9f5beff3836f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "#{\"username\":\"khwrali\",\"key\":\"a2b23dfbac2443ab4db34e48318ce4ff\"}\n",
        "od.download(\"https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufVfynSsdNvv",
        "outputId": "60ed28c2-56a9-4b21-c230-f915c6a457f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./imdb-dataset-of-50k-movie-reviews\" (use force=True to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n",
        "print(df.head(2))\n",
        "#Checking Missing values\n",
        "print(df.isnull().sum())\n",
        "#Checking number of positive and negative sentiments\n",
        "print(df['sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohVX25YTgyBS",
        "outputId": "93cb2386-da63-4dfd-96c2-b9f2259a895c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "review       0\n",
            "sentiment    0\n",
            "dtype: int64\n",
            "positive    25000\n",
            "negative    25000\n",
            "Name: sentiment, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df['clean_review'] = df['review'].apply(data_cleaning)"
      ],
      "metadata": {
        "id": "t60JlpAekXyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[['review', 'sentiment']].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9q36jfxkX4s",
        "outputId": "daf3868f-e1a4-464e-d2a2-c0ebe89359c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "5  Probably my all-time favorite movie, a story o...  positive\n",
            "6  I sure would like to see a resurrection of a u...  positive\n",
            "7  This show was an amazing, fresh & innovative i...  negative\n",
            "8  Encouraged by the positive comments about this...  negative\n",
            "9  If you like original gut wrenching laughter yo...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize two empty lists to store positive and negative reviews\n",
        "positive_reviews = []\n",
        "negative_reviews = []\n",
        "\n",
        "# Iterate through the DataFrame and separate reviews based on sentiment\n",
        "for _, row in df.iterrows():\n",
        "    if row['sentiment'] == 'positive':\n",
        "        positive_reviews.append(row['review'])\n",
        "    elif row['sentiment'] == 'negative':\n",
        "        negative_reviews.append(row['review'])\n",
        "\n",
        "# Print or use the positive_reviews and negative_reviews lists as needed\n",
        "print(\"Positive Reviews:\")\n",
        "print(positive_reviews[:1])\n",
        "\n",
        "\n",
        "print(\"\\nNegative Reviews:\")\n",
        "print(negative_reviews[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDAuQkTlkX67",
        "outputId": "fa758328-5c05-4155-e04c-056ca5feeea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive Reviews:\n",
            "[\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\"]\n",
            "\n",
            "Negative Reviews:\n",
            "[\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(positive_reviews))\n",
        "print(len(negative_reviews))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIUXnnXToSx3",
        "outputId": "9399725a-7c19-45cf-f81f-ce18ff6ae122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000\n",
            "25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into two pieces, one for training and one for testing (validation set)\n",
        "test_pos = positive_reviews[23000:]\n",
        "train_pos = positive_reviews[:23000]\n",
        "test_neg = negative_reviews[23000:]\n",
        "train_neg = negative_reviews[:23000]\n",
        "\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg"
      ],
      "metadata": {
        "id": "JYLXHuozoSzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
        "test_y = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))"
      ],
      "metadata": {
        "id": "nLlMxam5oS1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_reviews(result, reviews, ys):\n",
        "    '''\n",
        "    Input:\n",
        "        result: a dictionary that will be used to map each pair to its frequency\n",
        "        tweets: a list of tweets\n",
        "        ys: a list corresponding to the sentiment of each tweet (either 0 or 1)\n",
        "    Output:\n",
        "        result: a dictionary mapping each pair to its frequency\n",
        "    '''\n",
        "\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    for y, review in zip(ys, reviews):\n",
        "        for word in process_tweet(review):\n",
        "            # define the key, which is the word and label tuple\n",
        "            pair = (word,y)\n",
        "\n",
        "            # if the key exists in the dictionary, increment the count\n",
        "            if pair in result:\n",
        "                result[pair] += 1\n",
        "\n",
        "            # else, if the key is new, add it to the dictionary and set the count to 1\n",
        "            else:\n",
        "                result[pair] = 1\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "TMMSwTTpoS27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = count_reviews({}, train_x, train_y)"
      ],
      "metadata": {
        "id": "vm1cr2QKoS40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "def train_naive_bayes(freqs, train_x, train_y):\n",
        "    '''\n",
        "    Input:\n",
        "        freqs: dictionary from (word, label) to how often the word appears\n",
        "        train_x: a list of tweets\n",
        "        train_y: a list of labels correponding to the tweets (0,1)\n",
        "    Output:\n",
        "        logprior: the log prior. (equation 3 above)\n",
        "        loglikelihood: the log likelihood of you Naive bayes equation. (equation 6 above)\n",
        "    '''\n",
        "    loglikelihood = {}\n",
        "    logprior = 0\n",
        "\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "\n",
        "    # calculate V, the number of unique words in the vocabulary\n",
        "    vocab = set([pair[0] for pair in freqs.keys()])\n",
        "    V = len(vocab)\n",
        "\n",
        "    # calculate N_pos, N_neg, V_pos, V_neg\n",
        "    N_pos = N_neg = V_pos = V_neg = 0\n",
        "    for pair in freqs.keys():\n",
        "        # if the label is positive (greater than zero)\n",
        "        if pair[1] > 0:\n",
        "            # increment the count of unique positive words by 1\n",
        "            V_pos += 1\n",
        "\n",
        "            # Increment the number of positive words by the count for this (word, label) pair\n",
        "            N_pos += freqs[pair]\n",
        "\n",
        "        # else, the label is negative\n",
        "        else:\n",
        "            # increment the count of unique negative words by 1\n",
        "            V_neg += 1\n",
        "\n",
        "            # increment the number of negative words by the count for this (word,label) pair\n",
        "            N_neg += freqs[pair]\n",
        "\n",
        "    # Calculate D, the number of documents\n",
        "    D = len(train_y)\n",
        "\n",
        "    # Calculate D_pos, the number of positive documents\n",
        "    D_pos = (len(list(filter(lambda x: x > 0, train_y))))\n",
        "\n",
        "    # Calculate D_neg, the number of negative documents\n",
        "    D_neg = (len(list(filter(lambda x: x <= 0, train_y))))\n",
        "\n",
        "    # Calculate logprior\n",
        "    logprior = np.log(D_pos) - np.log(D_neg)\n",
        "\n",
        "    # For each word in the vocabulary...\n",
        "    for word in vocab:\n",
        "        # get the positive and negative frequency of the word\n",
        "        freq_pos = lookup(freqs,word,1)\n",
        "        freq_neg = lookup(freqs,word,0)\n",
        "\n",
        "        # calculate the probability that each word is positive, and negative\n",
        "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
        "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
        "\n",
        "        # calculate the log likelihood of the word\n",
        "        loglikelihood[word] = np.log(p_w_pos/p_w_neg)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return logprior, loglikelihood\n"
      ],
      "metadata": {
        "id": "rBewqN9EoS6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logprior, loglikelihood = train_naive_bayes(freqs, train_x, train_y)\n",
        "print(logprior)\n",
        "print(len(loglikelihood))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdKfV5DXoS8O",
        "outputId": "9e4e92c7-7df5-4d68-9b74-11233114f6bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "112397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        test_x: A list of tweets\n",
        "        test_y: the corresponding labels for the list of tweets\n",
        "        logprior: the logprior\n",
        "        loglikelihood: a dictionary with the loglikelihoods for each word\n",
        "    Output:\n",
        "        accuracy: (# of tweets classified correctly)/(total # of tweets)\n",
        "    \"\"\"\n",
        "    accuracy = 0  # return this properly\n",
        "\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    y_hats = []\n",
        "    for review in test_x:\n",
        "        # if the prediction is > 0\n",
        "        if naive_bayes_predict(review, logprior, loglikelihood) > 0:\n",
        "            # the predicted class is 1\n",
        "            y_hat_i = 1\n",
        "        else:\n",
        "            # otherwise the predicted class is 0\n",
        "            y_hat_i = 0\n",
        "\n",
        "        # append the predicted class to the list y_hats\n",
        "        y_hats.append(y_hat_i)\n",
        "\n",
        "    # error is the average of the absolute values of the differences between y_hats and test_y\n",
        "    error = np.mean(np.absolute(y_hats-test_y))\n",
        "\n",
        "    # Accuracy is 1 minus the error\n",
        "    accuracy = 1-error\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "tf55ueaPoTBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Naive Bayes accuracy = %0.4f\" %(test_naive_bayes(test_x, test_y, logprior, loglikelihood)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7SHK7X7oTEY",
        "outputId": "4be46f8e-449f-4fec-db7b-0044150a376d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy = 0.8558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "def naive_bayes_predict(review, logprior, loglikelihood):\n",
        "    '''\n",
        "    Input:\n",
        "        tweet: a string\n",
        "        logprior: a number\n",
        "        loglikelihood: a dictionary of words mapping to numbers\n",
        "    Output:\n",
        "        p: the sum of all the logliklihoods of each word in the tweet (if found in the dictionary) + logprior (a number)\n",
        "\n",
        "    '''\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    # process the tweet to get a list of words\n",
        "    word_l = process_tweet(review)\n",
        "\n",
        "    # initialize probability to zero\n",
        "    p = 0\n",
        "\n",
        "    # add the logprior\n",
        "    p += logprior\n",
        "\n",
        "    for word in word_l:\n",
        "\n",
        "        # check if the word exists in the loglikelihood dictionary\n",
        "        if word in loglikelihood:\n",
        "            # add the log likelihood of that word to the probability\n",
        "            p += loglikelihood[word]\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return p\n"
      ],
      "metadata": {
        "id": "ThiRxQl5oS-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_review = \"Having read the first few Harry Potter books before 2001 and hearing about the hype for the first movie, I was excited. I heard there was going to be an all-British cast (which makes sense, right?) and we'd get to see a live version of one of the defining novels of our generation. From what I remember I went with my family and a family friend to see the movie the day after Christmas and was pleasantly amazed. After the movie was over, I watched the credits and discovered some familiar names (the late Alan Rickman, Sister Act's Maggie Smith, James Bond 007's Robbie Coltrane, and Star Wars' Warwick Davis); others not so familiar (the kids, some of whom had their debut). But it was a good movie and was a party of colors and sights for all to see. This is easily my favorite of all the Harry Potter films. The catalyst of the movie series!\"\n",
        "p = naive_bayes_predict(my_review, logprior, loglikelihood)\n",
        "if p>0:\n",
        "  print(p,\"The review is positive\")\n",
        "else:\n",
        "  print(p,\"The review is negative\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kwhv9rnQoS_q",
        "outputId": "07e8c883-133a-4608-d4b4-1b7a2ed25860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.182934120203335 The review is positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ij4-_rjC070S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "coursera": {
      "schema_names": [
        "NLPC1-2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}